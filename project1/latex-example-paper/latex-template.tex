\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}	% For figure environment


\begin{document}
\title{Machine Learning Project 1 - Fall 2020}

\author{
  Julien Hu, Matthieu Masouye, Sebastien Ollquist\\
  \textit{Department of Computer Science, EPFL, Switzerland}
}

\maketitle

\begin{abstract}
  Implement basic Machine Learning methods on a given data set and analyze the predictions from it.
\end{abstract}

\section{Introduction}
The goal of this first mini project is to implement all basic Machine Learning methods on a given data set and analyze the results we obtained from running these algorithms. Essentially, the demanded algorithms were:
\begin{enumerate}
  \item Linear regression using Gradient Descent and Stochastic Gradient descent
  \item Least squares regression and ridge regression using normal equations
  \item Logistic regression using Gradient Descent
  \item Regularized logistic regression using Gradient Descent
\end{enumerate}

\section{Algorithms implementation details}
% --- TODO: WRITE HERE THE REST OF THE IMPLEMENTATION DETAILS OF EACH ALGORITHM
\subsection{Linear regression}
This first algorithm is essential to Machine Learning. It consists of taking a data set that often contains two different data point types and split them using a line described by a linear function in order to divide the points the best way possible. We have performed two different implementations of it: one using Gradient Descent (GD) and the other one using Stochastic Gradient Descent (SGD).\par
Note that the GD implementation does not work due to the fact that we are treating a big amount of data, so the SGD will help us resolve that problem by only taking a batch of for example 50 randomly selected data samples.\par
Before performing the algorithm we have to do two things:
\begin{enumerate}
  \item We first have to standardize the training data, that is given a variable $X$, we compute the value $Y=(X-\mu)/\sigma$ where $\mu$ is the computed mean and $\sigma$ the standard deviation.
  \item Then, we want to add a one in front of the $X^T$ matrix. This represents the bias which allows the linear function not to pass from the origin. In a function $y=ax+b$, $b$ is the bias.
\end{enumerate}
Once we have performed these steps, we can run the SGD algorithm on our data set.


\subsection{Least squares regression}

\subsection{Ridge regression}

\subsection{Logistic regression}

\section{Results obtained}
% --- WRITE HERE THE RESULTS OBTAINED FROM RUNNING THESE ALGORITHMS AND DISCUSS THE PREDICTIONS

\section{Conclusion}
% --- WRITE HERE A SMALL CONCLUSION TO THIS FIRST PROJECT

% \bibliographystyle{IEEEtran}
% \bibliography{literature}

\end{document}
